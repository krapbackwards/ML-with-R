---
title: "Naive Bayes particles"
author: "Joseph Park"
date: "4/11/2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## data and packages

```{r}

library(class)

library(tidyverse)

library(gmodels)

library(MLmetrics)

library(e1071)

library(naivebayes)

```

```{r}
particle <- read_csv("C:/Users/parkj/Documents/joe/ML with R/pid-5M.csv")
```
## sample (randomly) due to too much data for my laptop to process
```{r}
set.seed(47)
particles <- particle[sample(nrow(particle), 50000), ]

print(particles[complete.cases(particles) == FALSE, ])

print(which(is.na(particles)))
print(summary(particles))
for (i in 2:7){
  print(sd(as.matrix(particles[,i])))
}

#since one of the features has significantly higher variance (though probably not enough), we may want to transform, as this (among other things) can cause lower accuracy that can be remedied by transformation.  (We expect that z-score standardization will make no difference, because, although it is not stated in the book, the naiveBayes() classifier is probably Gaussian.)  Or, we can try removing that variable ('nphe').
```
```{r}
for (i in 2:7){
  hist(as.matrix(particles[,i]))
}

#looks like Poisson and/or multinomial, but not integers, so may want to try classifiers with different distribution (like gamma or beta) pdf's or discretize
```
## Split data

```{r}
particles_train <- particles[1:45000, 2:7]
particles_test <- particles[45001:50000, 2:7]

particles_train_labels <- particles[1:45000, 1]
particles_test_labels <- particles[45001:50000, 1]

```
## Train classifier on training data and classify test data

```{r}
#generating classification for different Laplace estimators to find best accuracy
accuracy = 1:2

for (i in 1:2){

  bayes_classifier <- naiveBayes(particles_train, as.factor(particles_train_labels[,1, drop = TRUE]), laplace = i-1)

  particles_test_pred <- predict(bayes_classifier, particles_test)
    
  #metric
  accuracy[i] <- Accuracy(particles_test_pred, particles_test_labels[,1, drop = TRUE])

#get best accurracy and corresponding index (with respect to Laplace estimator)
  if (i > 1){
    if (accuracy[i] > bestacc){
      bestacc <- accuracy[i]
      bestk <- i
    }
  } else {
    bestacc <- accuracy[i]
    bestk <- i
  }
}
```
## Metrics

```{r}
plot(accuracy[1:2])
print(paste("The best accuracy is", bestacc))
```
```{r}


CrossTable(x = particles_test_labels[,1, drop = TRUE], y = particles_test_pred, prop.chisq=FALSE)



```
# now normalized
```{r}
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}

particles[1:50000, 2:7] <- normalize(particles[1:50000, 2:7])


#To confirm that the transformation was applied correctly, let's look at one variable's summary statistics:
summary(particles)

for (i in 2:7){
  print(sd(as.matrix(particles[,i])))
}


```
```{r}
for (i in 2:7){
  hist(as.matrix(particles[,i]))
}


```
## Split data

```{r}
particles_train <- particles[1:45000, 2:7]
particles_test <- particles[45001:50000, 2:7]

particles_train_labels <- particles[1:45000, 1]
particles_test_labels <- particles[45001:50000, 1]

```
## Train classifier on training data and classify test data

```{r}
#generating classification for different Laplace estimator to find best accuracy
accuracy = 1:2

for (i in 1:2){

  bayes_classifier <- naiveBayes(particles_train, as.factor(particles_train_labels[,1, drop = TRUE]), laplace = i-1)

  particles_test_pred <- predict(bayes_classifier, particles_test)
    
  #metric
  accuracy[i] <- Accuracy(particles_test_pred, particles_test_labels[,1, drop = TRUE])

#get best accurracy and corresponding index (with respect to Laplace estimator)
  if (i > 1){
    if (accuracy[i] > bestacc){
      bestacc <- accuracy[i]
      bestk <- i
    }
  } else {
    bestacc <- accuracy[i]
    bestk <- i
  }
}
```
## Metrics

```{r}
plot(accuracy[1:2])
print(paste("The best accuracy is", bestacc))
```
```{r}


CrossTable(x = particles_test_labels[,1, drop = TRUE], y = particles_test_pred, prop.chisq=FALSE)



```
# Now z-standardized
```{r}

set.seed(47)
particles <- particle[sample(nrow(particle), 50000), ]

particles[1:50000, 2:7] <- as.data.frame(scale(particles[1:50000, 2:7]))


#To confirm that the transformation was applied correctly, let's look at one variable's summary statistics:
summary(particles)


for (i in 2:7){
  print(sd(as.matrix(particles[,i])))
}


```
```{r}
for (i in 2:7){
  hist(as.matrix(particles[,i]))
}


```
## Split data

```{r}
particles_train <- particles[1:45000, 2:7]
particles_test <- particles[45001:50000, 2:7]

particles_train_labels <- particles[1:45000, 1]
particles_test_labels <- particles[45001:50000, 1]

```
## Train classifier on training data and classify test data

```{r}
#generating classification for different Laplace estimators to find best accuracy
accuracy = 1:2

for (i in 1:2){

  bayes_classifier <- naiveBayes(particles_train, as.factor(particles_train_labels[,1, drop = TRUE]), laplace = i-1)

  particles_test_pred <- predict(bayes_classifier, particles_test)
    
  #metric
  accuracy[i] <- Accuracy(particles_test_pred, particles_test_labels[,1, drop = TRUE])

#get best accurracy and corresponding index (with respect to Laplace estimator)
  if (i > 1){
    if (accuracy[i] > bestacc){
      bestacc <- accuracy[i]
      bestk <- i
    }
  } else {
    bestacc <- accuracy[i]
    bestk <- i
  }
}
```
## Metrics

```{r}
plot(accuracy[1:2])
print(paste("The best accuracy is", bestacc))
```
```{r}


CrossTable(x = particles_test_labels[,1, drop = TRUE], y = particles_test_pred, prop.chisq=FALSE)

```

# Now with variable removals
```{r}

set.seed(47)
particles <- particle[sample(nrow(particle), 50000), ]

particles[1:50000, 2:7] <- as.data.frame(particles[1:50000, 2:7])




```
## Split data

```{r}
particles_train <- particles[1:45000, 2:7]
particles_test <- particles[45001:50000, 2:7]

particles_train_labels <- particles[1:45000, 1]
particles_test_labels <- particles[45001:50000, 1]

```
## Train classifier on training data and classify test data

```{r}
#generating classification for different variable removals to find best accuracy
accuracy = 2:7

for (i in 2:7){

 particles_train_r <- particles_train
 particles_train_r[,i] <- NULL

 particles_test_r <- particles_test
 particles_test_r[,i] <- NULL

 
  bayes_classifier <- naiveBayes(particles_train_r, as.factor(particles_train_labels[,1, drop = TRUE]))

  particles_test_pred_r <- predict(bayes_classifier, particles_test_r)
    
  #metric
  accuracy[i] <- Accuracy(particles_test_pred_r, particles_test_labels[,1, drop = TRUE])

#get best accurracy and corresponding index (with respect to variable removal)
  if (i > 2){
    if (accuracy[i] > bestacc){
      bestacc <- accuracy[i]
      bestk <- i
    }
  } else {
    bestacc <- accuracy[i]
    bestk <- i
    print(i)
  }
}

```
## Metrics

```{r}
plot(accuracy[2:7])
print(paste("The best accuracy is", bestacc))
```
```{r}
 particles_train_r <- particles_train
 particles_train_r[,bestk] <- NULL

 particles_test_r <- particles_test
 particles_test_r[,bestk] <- NULL

 
  bayes_classifier <- naiveBayes(particles_train_r, as.factor(particles_train_labels[,1, drop = TRUE]))

  particles_test_pred_r <- predict(bayes_classifier, particles_test_r)

CrossTable(x = particles_test_labels[,1, drop = TRUE], y = particles_test_pred_r, prop.chisq=FALSE)

```